



@article{Kostere2106028118,
        author = {K{\"o}ster, Raphael and Hadfield-Menell, Dylan and Everett, Richard and Weidinger, Laura and Hadfield, Gillian K. and Leibo, Joel Z.},
        title = {Spurious normativity enhances learning of compliance and enforcement behavior in artificial agents},
        volume = {119},
        number = {3},
        elocation-id = {e2106028118},
        year = {2022},
        doi = {10.1073/pnas.2106028118},
        publisher = {National Academy of Sciences},
        abstract = {The fact that humans enforce and comply with norms is an important reason why humans enjoy higher levels of cooperation and welfare than other animals. Some norms are relatively easy to explain: They may prohibit obviously harmful or uncooperative actions. But many norms are not easy to explain. For example, most cultures prohibit eating certain kinds of foods, and almost all societies have rules about what constitutes appropriate clothing, language, and gestures. Using a computational model focused on learning shows that apparently pointless rules can have an indirect effect on welfare. They can help agents learn how to enforce and comply with norms in general, improving the group{\textquoteright}s ability to enforce norms that have a direct effect on welfare.How do societies learn and maintain social norms? Here we use multiagent reinforcement learning to investigate the learning dynamics of enforcement and compliance behaviors. Artificial agents populate a foraging environment and need to learn to avoid a poisonous berry. Agents learn to avoid eating poisonous berries better when doing so is taboo, meaning the behavior is punished by other agents. The taboo helps overcome a credit assignment problem in discovering delayed health effects. Critically, introducing an additional taboo, which results in punishment for eating a harmless berry, further improves overall returns. This {\textquotedblleft}silly rule{\textquotedblright} counterintuitively has a positive effect because it gives agents more practice in learning rule enforcement. By probing what individual agents have learned, we demonstrate that normative behavior relies on a sequence of learned skills. Learning rule compliance builds upon prior learning of rule enforcement by other agents. Our results highlight the benefit of employing a multiagent reinforcement learning computational model focused on learning to implement complex actions.Learning trajectories from the simulation displayed in the plots have been deposited in GitHub (https://github.com/deepmind/spurious_normativity).},
        issn = {0027-8424},
        URL = {https://www.pnas.org/content/119/3/e2106028118},
        eprint = {https://www.pnas.org/content/119/3/e2106028118.full.pdf},
        journal = {Proceedings of the National Academy of Sciences},
        file={Biblio/DomainSpecific/ArtificialLife/e2106028118.full.pdf}
}




@incollection{denaro1997cultural,
  title={Cultural evolution in a population of neural networks},
  author={Denaro, Daniele and Parisi, Domenico},
  booktitle={Neural Nets WIRN VIETRI-96},
  pages={100--111},
  year={1997},
  publisher={Springer}
}

@article{stanley2002evolving,
  title={Evolving neural networks through augmenting topologies},
  author={Stanley, Kenneth O and Miikkulainen, Risto},
  journal={Evolutionary computation},
  volume={10},
  number={2},
  pages={99--127},
  year={2002},
  publisher={MIT Press}
}

@article{beer1992evolving,
  title={Evolving dynamical neural networks for adaptive behavior},
  author={Beer, Randall D and Gallagher, John C},
  journal={Adaptive behavior},
  volume={1},
  number={1},
  pages={91--122},
  year={1992},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}


@article{nolfi1994learning,
  title={Learning and evolution in neural networks},
  author={Nolfi, Stefano and Parisi, Domenico and Elman, Jeffrey L},
  journal={Adaptive Behavior},
  volume={3},
  number={1},
  pages={5--28},
  year={1994},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}


@article{cangelosi1998emergence,
  title={The emergence of a'language'in an evolving population of neural networks},
  author={Cangelosi, Angelo and Parisi, Domenico},
  journal={Connection Science},
  volume={10},
  number={2},
  pages={83--97},
  year={1998},
  publisher={Taylor \& Francis}
}

@article{lund1995preadaptation,
  title={Preadaptation in populations of neural networks evolving in a changing environment},
  author={Lund, Henrik Hautop and Parisi, Domenico},
  journal={Artificial Life},
  volume={2},
  number={2},
  pages={179--197},
  year={1995},
  publisher={MIT Press}
}

@inproceedings{bruce2001evolving,
  title={Evolving populations of expert neural networks},
  author={Bruce, Joseph and Miikkulainen, Risto},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference (GECCO-2001)},
  pages={251--257},
  year={2001}
}

@article{mirjalili2014let,
  title={Let a biogeography-based optimizer train your multi-layer perceptron},
  author={Mirjalili, Seyedali and Mirjalili, Seyed Mohammad and Lewis, Andrew},
  journal={Information Sciences},
  volume={269},
  pages={188--209},
  year={2014},
  publisher={Elsevier}
}

